{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# High-dimensional Data Analysis"
      ],
      "id": "213472d1-eec9-404c-9d48-c36d05776480"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import gradio as gr"
      ],
      "id": "3172a779"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "High-dimensional data analysis is a common requirement in modern\n",
        "statistics and machine learning. It involves understanding data where\n",
        "the number of features (dimensions) greatly exceeds the number of\n",
        "samples. This notebook explores several fundamental concepts and\n",
        "theoretical tools to navigate and analyze high-dimensional datasets\n",
        "effectively.\n",
        "\n",
        "**Chebyshev’s Inequality**\n",
        "\n",
        "A statistical bound that estimates the probability deviations of a\n",
        "random variable from its mean, applicable to any distribution with a\n",
        "finite variance. Formally:\n",
        "\n",
        "$$\n",
        "P(|X - EX| \\geq t) \\leq \\frac{\\text{Var}(X)}{t^2}\n",
        "$$\n",
        "\n",
        "We demonstrate this using a uniformly distributed random variable to\n",
        "show how bounds hold against actual probability calculations.\n",
        "\n",
        "**Weak Law of Large Numbers (WLLN)**\n",
        "\n",
        "This principle asserts that, with an increasing number of independent\n",
        "samples, the sample mean approaches the expected value with high\n",
        "probability\n",
        "\n",
        "$$\n",
        "\\lim_{n \\to \\infty} P(|S_n - \\mu| \\geq \\epsilon) = 0, \\quad \\forall \\epsilon > 0\n",
        "$$\n",
        "\n",
        "We illustrate this with Bernoulli trials to observe convergence\n",
        "behavior.\n",
        "\n",
        "**High-dimensional Geometry**\n",
        "\n",
        "As dimensionality increases, random vectors tend toward orthogonality\n",
        "(they become nearly perpendicular). For independent vectors drawn from a\n",
        "normal distribution:\n",
        "\n",
        "$$\n",
        "P\\left(\\frac{| \\langle X, Y \\rangle |}{||X|| \\cdot ||Y||} \\geq t \\right) \\leq \\frac{1}{dt^2}\n",
        "$$\n",
        "\n",
        "As dimensions grow, vector angles tend to small values infrequently,\n",
        "highlighting dimensionality’s role.\n",
        "\n",
        "**Johnson-Lindenstrauss Lemma**\n",
        "\n",
        "An important dimensionality reduction result, ensuring that\n",
        "high-dimensional data can be projected into lower-dimensional spaces\n",
        "with minimal distortion of pairwise distances.\n",
        "\n",
        "## Python Implementation\n",
        "\n",
        "Implementing Chebyshev’s inequality for a uniformly distributed random\n",
        "variable, we compare actual and theoretical probabilities."
      ],
      "id": "9462bcb5-5e0a-4ca7-b82d-d983f4b32751"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chebyshev_uniform_demo(t: float) -> tuple[float, float, dict]:\n",
        "    \"\"\"\n",
        "    Demonstrates Chebyshev inequality for X ~ Uniform[0,1]\n",
        "    Returns (actual_prob, bound_prob, stats)\n",
        "    \"\"\"\n",
        "    actual_prob = 1 - 2 * t if 0 < t < 0.5 else 0.0\n",
        "    var = 1 / 12\n",
        "    bound_prob = min(var / t**2, 1.0) if t > 0 else 1.0\n",
        "    stats = {\n",
        "        \"mean\": 0.5,\n",
        "        \"variance\": var,\n",
        "        \"threshold\": t,\n",
        "        \"actual_probability\": actual_prob,\n",
        "        \"chebyshev_bound\": bound_prob,\n",
        "    }\n",
        "    return actual_prob, bound_prob, stats"
      ],
      "id": "98ae4951"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We simulate the Weak Law of Large Numbers (WLLN) using Bernoulli trials\n",
        "and observe how sample means approach the expected value."
      ],
      "id": "b0097ed8-3fd6-45ca-835b-c72a8f5b3b97"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wlln_simulation(n: int, num_samples: int = 1000) -> dict:\n",
        "    \"\"\"Simulates Weak Law of Large Numbers for Bernoulli trials\"\"\"\n",
        "    samples = np.random.binomial(1, 0.5, (num_samples, n))\n",
        "    sample_means = samples.mean(axis=1)\n",
        "    stats = {\n",
        "        \"expected_mean\": 0.5,\n",
        "        \"sample_means_mean\": sample_means.mean(),\n",
        "        \"sample_means_var\": sample_means.var(),\n",
        "        \"chebyshev_bound\": 1 / (4 * n * 0.05**2),  # For ε=0.05\n",
        "    }\n",
        "    return stats"
      ],
      "id": "8917a45d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `high_dim_orthogonality` function helps us to understand the\n",
        "geometry of high dimensions by checking the orthogonality between random\n",
        "vectors:"
      ],
      "id": "015eece4-4494-4400-b688-db9f5f45c97e"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def high_dim_orthogonality(d: int, num_pairs: int = 1000) -> dict:\n",
        "    \"\"\"Calculates inner product statistics in high dimensions\"\"\"\n",
        "    X = np.random.normal(0, 1, (num_pairs, d))\n",
        "    Y = np.random.normal(0, 1, (num_pairs, d))\n",
        "    norms_X = np.linalg.norm(X, axis=1)\n",
        "    norms_Y = np.linalg.norm(Y, axis=1)\n",
        "    cos_theta = np.sum(X * Y, axis=1) / (norms_X * norms_Y)\n",
        "    stats = {\n",
        "        \"mean_angle\": np.mean(np.arccos(cos_theta)),\n",
        "        \"prob_above_0.1\": np.mean(np.abs(cos_theta) > 0.1),\n",
        "        \"chebyshev_bound\": 1 / (d * 0.1**2),\n",
        "    }\n",
        "    return stats"
      ],
      "id": "5bd3cdad"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With `johnson_lindenstrauss_project` we perform random projection as per\n",
        "the Johnson-Lindenstrauss Lemma to dimensionality reduction while\n",
        "preserving distances."
      ],
      "id": "dbb2d335-5013-4d5e-877a-7c66fe104fef"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def johnson_lindenstrauss_project(X: np.ndarray, k: int) -> np.ndarray:\n",
        "    \"\"\"Random projection matrix for JL Lemma\"\"\"\n",
        "    d = X.shape[1]\n",
        "    Q = np.random.normal(0, 1 / np.sqrt(k), (d, k))\n",
        "    return X @ Q"
      ],
      "id": "07be6cbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Dashboard"
      ],
      "id": "5541b68b-0b8b-443e-8565-d0d8bcf8cd2d"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks(\n",
        "    css=\"\"\"gradio-app {background: #222222 !important}\"\"\",\n",
        "    title=\"High-Dimensional Data Behavior\",\n",
        ") as demo:\n",
        "    with gr.Tab(\"Chebyshev Inequality\"):\n",
        "        t_input = gr.Slider(0.01, 0.49, value=0.2, label=\"Threshold t\")\n",
        "        cheb_plot = gr.Plot()\n",
        "        cheb_json = gr.JSON()\n",
        "\n",
        "        def update_cheb(t):\n",
        "            actual, bound, stats = chebyshev_uniform_demo(t)\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=np.linspace(0, 1, 100), y=[0.5] * 100, name=\"Mean\")\n",
        "            )\n",
        "            fig.add_vrect(\n",
        "                x0=0.5 - t,\n",
        "                x1=0.5 + t,\n",
        "                fillcolor=\"green\",\n",
        "                opacity=0.2,\n",
        "                name=\"Acceptance\",\n",
        "            )\n",
        "            fig.update_layout(title=\"Probability Concentration: Actual vs Bound\")\n",
        "            cheb_json = stats\n",
        "            return fig, cheb_json\n",
        "\n",
        "        t_input.change(update_cheb, t_input, [cheb_plot, cheb_json])\n",
        "        demo.load(update_cheb, t_input, [cheb_plot, cheb_json])\n",
        "\n",
        "    with gr.Tab(\"Weak Law of Large Numbers\"):\n",
        "        n_input = gr.Slider(10, 1000, value=100, step=10, label=\"Sample size n\")\n",
        "        wlln_plot = gr.Plot()\n",
        "\n",
        "        def update_wlln(n):\n",
        "            means = [wlln_simulation(int(n))[\"sample_means_mean\"] for _ in range(100)]\n",
        "            fig = px.line(\n",
        "                x=range(100),\n",
        "                y=means,\n",
        "                labels={\"x\": \"Trial\", \"y\": \"Sample Mean\"},\n",
        "                title=\"Convergence of Sample Means\",\n",
        "            )\n",
        "            fig.add_hline(y=0.5, line_dash=\"dash\")\n",
        "            return fig\n",
        "\n",
        "        n_input.change(update_wlln, n_input, wlln_plot)\n",
        "        demo.load(update_wlln, n_input, wlln_plot)\n",
        "\n",
        "    with gr.Tab(\"High-D Orthogonality\"):\n",
        "        dim_input = gr.Slider(2, 1000, value=100, label=\"Dimension d\")\n",
        "        angle_plot = gr.Plot()\n",
        "        angle_stats = gr.JSON()\n",
        "\n",
        "        def update_angles(d):\n",
        "            stats = high_dim_orthogonality(int(d))\n",
        "            angles = np.random.normal(0, 1 / np.sqrt(d), 1000)\n",
        "            fig = px.histogram(\n",
        "                angles, nbins=50, title=\"Distribution of cosθ in High Dimensions\"\n",
        "            )\n",
        "            angle_stats = stats\n",
        "            return fig, angle_stats\n",
        "\n",
        "        dim_input.change(update_angles, dim_input, [angle_plot, angle_stats])\n",
        "        demo.load(update_angles, dim_input, [angle_plot, angle_stats])"
      ],
      "id": "8f4569e6"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "demo.launch(pwa=True, show_api=False, show_error=True)"
      ],
      "id": "c32f0e81"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Browser Compatibility**\n",
        ">\n",
        "> Note that the in-browser Gradio Lite interface is supported only on\n",
        "> modern desktop browsers. If you are using a mobile device or an older\n",
        "> browser, you may encounter WebAssembly-related errors."
      ],
      "id": "3516154d-6ef2-4b1f-a780-998c6199b48b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "    <div style=\"width: 100%;\">\n",
              "        <script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n",
              "        <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n",
              "        <style>\n",
              "            gradio-lite {\n",
              "                background: #222222 !important;\n",
              "                border: white 1px solid !important;\n",
              "                width: 100% !important;\n",
              "            }\n",
              "            .column {\n",
              "                width: 100% !important;\n",
              "            }\n",
              "        </style>\n",
              "        <gradio-lite>\n",
              "import micropip\n",
              "await micropip.install(&#x27;plotly==5.24.1&#x27;);\n",
              "\n",
              "\n",
              "import numpy as np\n",
              "import plotly.express as px\n",
              "import plotly.graph_objects as go\n",
              "import gradio as gr\n",
              "def chebyshev_uniform_demo(t: float) -&gt; tuple[float, float, dict]:\n",
              "    &quot;&quot;&quot;\n",
              "    Demonstrates Chebyshev inequality for X ~ Uniform[0,1]\n",
              "    Returns (actual_prob, bound_prob, stats)\n",
              "    &quot;&quot;&quot;\n",
              "    actual_prob = 1 - 2 * t if 0 &lt; t &lt; 0.5 else 0.0\n",
              "    var = 1 / 12\n",
              "    bound_prob = min(var / t**2, 1.0) if t &gt; 0 else 1.0\n",
              "    stats = {\n",
              "        &quot;mean&quot;: 0.5,\n",
              "        &quot;variance&quot;: var,\n",
              "        &quot;threshold&quot;: t,\n",
              "        &quot;actual_probability&quot;: actual_prob,\n",
              "        &quot;chebyshev_bound&quot;: bound_prob,\n",
              "    }\n",
              "    return actual_prob, bound_prob, stats\n",
              "def wlln_simulation(n: int, num_samples: int = 1000) -&gt; dict:\n",
              "    &quot;&quot;&quot;Simulates Weak Law of Large Numbers for Bernoulli trials&quot;&quot;&quot;\n",
              "    samples = np.random.binomial(1, 0.5, (num_samples, n))\n",
              "    sample_means = samples.mean(axis=1)\n",
              "    stats = {\n",
              "        &quot;expected_mean&quot;: 0.5,\n",
              "        &quot;sample_means_mean&quot;: sample_means.mean(),\n",
              "        &quot;sample_means_var&quot;: sample_means.var(),\n",
              "        &quot;chebyshev_bound&quot;: 1 / (4 * n * 0.05**2),  # For ε=0.05\n",
              "    }\n",
              "    return stats\n",
              "def high_dim_orthogonality(d: int, num_pairs: int = 1000) -&gt; dict:\n",
              "    &quot;&quot;&quot;Calculates inner product statistics in high dimensions&quot;&quot;&quot;\n",
              "    X = np.random.normal(0, 1, (num_pairs, d))\n",
              "    Y = np.random.normal(0, 1, (num_pairs, d))\n",
              "    norms_X = np.linalg.norm(X, axis=1)\n",
              "    norms_Y = np.linalg.norm(Y, axis=1)\n",
              "    cos_theta = np.sum(X * Y, axis=1) / (norms_X * norms_Y)\n",
              "    stats = {\n",
              "        &quot;mean_angle&quot;: np.mean(np.arccos(cos_theta)),\n",
              "        &quot;prob_above_0.1&quot;: np.mean(np.abs(cos_theta) &gt; 0.1),\n",
              "        &quot;chebyshev_bound&quot;: 1 / (d * 0.1**2),\n",
              "    }\n",
              "    return stats\n",
              "def johnson_lindenstrauss_project(X: np.ndarray, k: int) -&gt; np.ndarray:\n",
              "    &quot;&quot;&quot;Random projection matrix for JL Lemma&quot;&quot;&quot;\n",
              "    d = X.shape[1]\n",
              "    Q = np.random.normal(0, 1 / np.sqrt(k), (d, k))\n",
              "    return X @ Q\n",
              "with gr.Blocks(\n",
              "    css=&quot;&quot;&quot;gradio-app {background: #222222 !important}&quot;&quot;&quot;,\n",
              "    title=&quot;High-Dimensional Data Behavior&quot;,\n",
              ") as demo:\n",
              "    with gr.Tab(&quot;Chebyshev Inequality&quot;):\n",
              "        t_input = gr.Slider(0.01, 0.49, value=0.2, label=&quot;Threshold t&quot;)\n",
              "        cheb_plot = gr.Plot()\n",
              "        cheb_json = gr.JSON()\n",
              "\n",
              "        def update_cheb(t):\n",
              "            actual, bound, stats = chebyshev_uniform_demo(t)\n",
              "            fig = go.Figure()\n",
              "            fig.add_trace(\n",
              "                go.Scatter(x=np.linspace(0, 1, 100), y=[0.5] * 100, name=&quot;Mean&quot;)\n",
              "            )\n",
              "            fig.add_vrect(\n",
              "                x0=0.5 - t,\n",
              "                x1=0.5 + t,\n",
              "                fillcolor=&quot;green&quot;,\n",
              "                opacity=0.2,\n",
              "                name=&quot;Acceptance&quot;,\n",
              "            )\n",
              "            fig.update_layout(title=&quot;Probability Concentration: Actual vs Bound&quot;)\n",
              "            cheb_json = stats\n",
              "            return fig, cheb_json\n",
              "\n",
              "        t_input.change(update_cheb, t_input, [cheb_plot, cheb_json])\n",
              "        demo.load(update_cheb, t_input, [cheb_plot, cheb_json])\n",
              "\n",
              "    with gr.Tab(&quot;Weak Law of Large Numbers&quot;):\n",
              "        n_input = gr.Slider(10, 1000, value=100, step=10, label=&quot;Sample size n&quot;)\n",
              "        wlln_plot = gr.Plot()\n",
              "\n",
              "        def update_wlln(n):\n",
              "            means = [wlln_simulation(int(n))[&quot;sample_means_mean&quot;] for _ in range(100)]\n",
              "            fig = px.line(\n",
              "                x=range(100),\n",
              "                y=means,\n",
              "                labels={&quot;x&quot;: &quot;Trial&quot;, &quot;y&quot;: &quot;Sample Mean&quot;},\n",
              "                title=&quot;Convergence of Sample Means&quot;,\n",
              "            )\n",
              "            fig.add_hline(y=0.5, line_dash=&quot;dash&quot;)\n",
              "            return fig\n",
              "\n",
              "        n_input.change(update_wlln, n_input, wlln_plot)\n",
              "        demo.load(update_wlln, n_input, wlln_plot)\n",
              "\n",
              "    with gr.Tab(&quot;High-D Orthogonality&quot;):\n",
              "        dim_input = gr.Slider(2, 1000, value=100, label=&quot;Dimension d&quot;)\n",
              "        angle_plot = gr.Plot()\n",
              "        angle_stats = gr.JSON()\n",
              "\n",
              "        def update_angles(d):\n",
              "            stats = high_dim_orthogonality(int(d))\n",
              "            angles = np.random.normal(0, 1 / np.sqrt(d), 1000)\n",
              "            fig = px.histogram(\n",
              "                angles, nbins=50, title=&quot;Distribution of cosθ in High Dimensions&quot;\n",
              "            )\n",
              "            angle_stats = stats\n",
              "            return fig, angle_stats\n",
              "\n",
              "        dim_input.change(update_angles, dim_input, [angle_plot, angle_stats])\n",
              "        demo.load(update_angles, dim_input, [angle_plot, angle_stats])\n",
              "demo.launch(pwa=True, show_api=False, show_error=True)\n",
              "\n",
              "        </gradio-lite>\n",
              "    </div>\n",
              "    "
            ]
          }
        }
      ],
      "source": [
        "# Output of this cell set dynamically in Quarto filter step"
      ],
      "id": "gradio-lite"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": ".venv",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  }
}