{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# High-dimensional Data Analysis"
      ],
      "id": "3e02dfb5-aa2f-4578-ab3e-452bf724c0df"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import gradio as gr"
      ],
      "id": "3172a779"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "High-dimensional data analysis is essential in modern statistics and\n",
        "machine learning. It involves understanding data where the number of\n",
        "features (dimensions) greatly exceeds the number of samples. This\n",
        "notebook explores several fundamental concepts and theoretical tools to\n",
        "navigate and analyze high-dimensional datasets effectively:\n",
        "\n",
        "1.  **Chebyshev’s Inequality**: A statistical bound that estimates the\n",
        "    probability deviations of a random variable from its mean,\n",
        "    applicable to any distribution with a finite variance. Formally:\n",
        "\n",
        "    $$\n",
        "    P(|X - EX| \\geq t) \\leq \\frac{\\text{Var}(X)}{t^2}\n",
        "    $$\n",
        "\n",
        "    We demonstrate this using a uniformly distributed random variable to\n",
        "    show how bounds hold against actual probability calculations.\n",
        "\n",
        "2.  **Weak Law of Large Numbers (WLLN)**:\n",
        "\n",
        "    -   This principle asserts that, with an increasing number of\n",
        "        independent samples, the sample mean approaches the expected\n",
        "        value with high probability:\n",
        "\n",
        "        $$\n",
        "        \\lim_{n \\to \\infty} P(|S_n - \\mu| \\geq \\epsilon) = 0, \\quad \\forall \\epsilon > 0\n",
        "        $$\n",
        "\n",
        "    -   We illustrate this with Bernoulli trials to observe convergence\n",
        "        behavior.\n",
        "\n",
        "3.  **High-dimensional Geometry**:\n",
        "\n",
        "    -   As dimensionality increases, random vectors tend toward\n",
        "        orthogonality (they become nearly perpendicular). For\n",
        "        independent vectors drawn from a normal distribution:\n",
        "\n",
        "        $$\n",
        "        P\\left(\\frac{| \\langle X, Y \\rangle |}{||X|| \\cdot ||Y||} \\geq t \\right) \\leq \\frac{1}{dt^2}\n",
        "        $$\n",
        "\n",
        "    -   As dimensions grow, vector angles tend to small values\n",
        "        infrequently, highlighting dimensionality’s role.\n",
        "\n",
        "4.  **Johnson-Lindenstrauss Lemma**:\n",
        "\n",
        "    -   An important dimensionality reduction result, ensuring that\n",
        "        high-dimensional data can be projected into lower-dimensional\n",
        "        spaces with minimal distortion of pairwise distances.\n",
        "\n",
        "## Python Implementation\n",
        "\n",
        "Implementing Chebyshev’s inequality for a uniformly distributed random\n",
        "variable, we compare actual and theoretical probabilities:"
      ],
      "id": "98e5fcb0-78ad-40f3-bcbb-1b28b8488d9d"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chebyshev_uniform_demo(t: float) -> tuple[float, float, dict]:\n",
        "    \"\"\"\n",
        "    Demonstrates Chebyshev inequality for X ~ Uniform[0,1]\n",
        "    Returns (actual_prob, bound_prob, stats)\n",
        "    \"\"\"\n",
        "    actual_prob = 1 - 2 * t if 0 < t < 0.5 else 0.0\n",
        "    var = 1 / 12\n",
        "    bound_prob = min(var / t**2, 1.0) if t > 0 else 1.0\n",
        "    stats = {\n",
        "        \"mean\": 0.5,\n",
        "        \"variance\": var,\n",
        "        \"threshold\": t,\n",
        "        \"actual_probability\": actual_prob,\n",
        "        \"chebyshev_bound\": bound_prob,\n",
        "    }\n",
        "    return actual_prob, bound_prob, stats"
      ],
      "id": "98ae4951"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulate the Weak Law of Large Numbers (WLLN) using Bernoulli trials and\n",
        "observe how sample means approach the expected value:"
      ],
      "id": "65c176fc-bacc-4277-9448-2f73dc41c0fa"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wlln_simulation(n: int, num_samples: int = 1000) -> dict:\n",
        "    \"\"\"Simulates Weak Law of Large Numbers for Bernoulli trials\"\"\"\n",
        "    samples = np.random.binomial(1, 0.5, (num_samples, n))\n",
        "    sample_means = samples.mean(axis=1)\n",
        "    stats = {\n",
        "        \"expected_mean\": 0.5,\n",
        "        \"sample_means_mean\": sample_means.mean(),\n",
        "        \"sample_means_var\": sample_means.var(),\n",
        "        \"chebyshev_bound\": 1 / (4 * n * 0.05**2),  # For ε=0.05\n",
        "    }\n",
        "    return stats"
      ],
      "id": "8917a45d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Understand the geometry of high dimensions by checking the orthogonality\n",
        "between random vectors:"
      ],
      "id": "9dfe729a-8e8c-42fb-b67c-ab66158190d1"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def high_dim_orthogonality(d: int, num_pairs: int = 1000) -> dict:\n",
        "    \"\"\"Calculates inner product statistics in high dimensions\"\"\"\n",
        "    X = np.random.normal(0, 1, (num_pairs, d))\n",
        "    Y = np.random.normal(0, 1, (num_pairs, d))\n",
        "    norms_X = np.linalg.norm(X, axis=1)\n",
        "    norms_Y = np.linalg.norm(Y, axis=1)\n",
        "    cos_theta = np.sum(X * Y, axis=1) / (norms_X * norms_Y)\n",
        "    stats = {\n",
        "        \"mean_angle\": np.mean(np.arccos(cos_theta)),\n",
        "        \"prob_above_0.1\": np.mean(np.abs(cos_theta) > 0.1),\n",
        "        \"chebyshev_bound\": 1 / (d * 0.1**2),\n",
        "    }\n",
        "    return stats"
      ],
      "id": "5bd3cdad"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform random projection as per the Johnson-Lindenstrauss Lemma to\n",
        "dimensionality reduction while preserving distances:"
      ],
      "id": "8093624d-fa58-4615-b9e5-fe72bfdf308b"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def johnson_lindenstrauss_project(X: np.ndarray, k: int) -> np.ndarray:\n",
        "    \"\"\"Random projection matrix for JL Lemma\"\"\"\n",
        "    d = X.shape[1]\n",
        "    Q = np.random.normal(0, 1 / np.sqrt(k), (d, k))\n",
        "    return X @ Q"
      ],
      "id": "07be6cbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Dashboard\n",
        "\n",
        "Using Gradio, this interactive interface allows exploring theoretical\n",
        "concepts with adjustable parameters and visualization:"
      ],
      "id": "e9fe9f3d-8309-41d3-98ad-32574dccb5bd"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks(\n",
        "    css=\"\"\"gradio-app {background: #222222 !important}\"\"\",\n",
        "    title=\"High-Dimensional Data Behavior\",\n",
        ") as demo:\n",
        "    with gr.Tab(\"Chebyshev Inequality\"):\n",
        "        t_input = gr.Slider(0.01, 0.49, value=0.2, label=\"Threshold t\")\n",
        "        cheb_plot = gr.Plot()\n",
        "        cheb_json = gr.JSON()\n",
        "\n",
        "        def update_cheb(t):\n",
        "            actual, bound, stats = chebyshev_uniform_demo(t)\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=np.linspace(0, 1, 100), y=[0.5] * 100, name=\"Mean\")\n",
        "            )\n",
        "            fig.add_vrect(\n",
        "                x0=0.5 - t,\n",
        "                x1=0.5 + t,\n",
        "                fillcolor=\"green\",\n",
        "                opacity=0.2,\n",
        "                name=\"Acceptance\",\n",
        "            )\n",
        "            fig.update_layout(title=\"Probability Concentration: Actual vs Bound\")\n",
        "            cheb_json = stats\n",
        "            return fig, cheb_json\n",
        "\n",
        "        t_input.change(update_cheb, t_input, [cheb_plot, cheb_json])\n",
        "\n",
        "    with gr.Tab(\"Weak Law of Large Numbers\"):\n",
        "        n_input = gr.Slider(10, 1000, value=100, step=10, label=\"Sample size n\")\n",
        "        wlln_plot = gr.Plot()\n",
        "\n",
        "        def update_wlln(n):\n",
        "            means = [wlln_simulation(int(n))[\"sample_means_mean\"] for _ in range(100)]\n",
        "            fig = px.line(\n",
        "                x=range(100),\n",
        "                y=means,\n",
        "                labels={\"x\": \"Trial\", \"y\": \"Sample Mean\"},\n",
        "                title=\"Convergence of Sample Means\",\n",
        "            )\n",
        "            fig.add_hline(y=0.5, line_dash=\"dash\")\n",
        "            return fig\n",
        "\n",
        "        n_input.change(update_wlln, n_input, wlln_plot)\n",
        "\n",
        "    with gr.Tab(\"High-D Orthogonality\"):\n",
        "        dim_input = gr.Slider(2, 1000, value=100, label=\"Dimension d\")\n",
        "        angle_plot = gr.Plot()\n",
        "        angle_stats = gr.JSON()\n",
        "\n",
        "        def update_angles(d):\n",
        "            stats = high_dim_orthogonality(int(d))\n",
        "            angles = np.random.normal(0, 1 / np.sqrt(d), 1000)\n",
        "            fig = px.histogram(\n",
        "                angles, nbins=50, title=\"Distribution of cosθ in High Dimensions\"\n",
        "            )\n",
        "            angle_stats = stats\n",
        "            return fig, angle_stats\n",
        "\n",
        "        dim_input.change(update_angles, dim_input, [angle_plot, angle_stats])"
      ],
      "id": "8f4569e6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [
          "ignore"
        ]
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "    <div style=\"width: 100%;\">\n",
              "        <script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n",
              "        <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n",
              "        <style>\n",
              "            gradio-lite {\n",
              "                background: #222222 !important;\n",
              "                border: white 1px solid !important;\n",
              "                width: 100% !important;\n",
              "            }\n",
              "            .column {\n",
              "                width: 100% !important;\n",
              "            }\n",
              "        </style>\n",
              "        <gradio-lite>\n",
              "import micropip\n",
              "await micropip.install('plotly==5.24.1');\n",
              "import numpy as np\n",
              "import plotly.express as px\n",
              "import plotly.graph_objects as go\n",
              "import gradio as gr\n",
              "def chebyshev_uniform_demo(t: float) -&gt; tuple[float, float, dict]:\n",
              "    &quot;&quot;&quot;\n",
              "    Demonstrates Chebyshev inequality for X ~ Uniform[0,1]\n",
              "    Returns (actual_prob, bound_prob, stats)\n",
              "    &quot;&quot;&quot;\n",
              "    actual_prob = 1 - 2 * t if 0 &lt; t &lt; 0.5 else 0.0\n",
              "    var = 1 / 12\n",
              "    bound_prob = min(var / t**2, 1.0) if t &gt; 0 else 1.0\n",
              "    stats = {\n",
              "        &quot;mean&quot;: 0.5,\n",
              "        &quot;variance&quot;: var,\n",
              "        &quot;threshold&quot;: t,\n",
              "        &quot;actual_probability&quot;: actual_prob,\n",
              "        &quot;chebyshev_bound&quot;: bound_prob,\n",
              "    }\n",
              "    return actual_prob, bound_prob, stats\n",
              "def wlln_simulation(n: int, num_samples: int = 1000) -&gt; dict:\n",
              "    &quot;&quot;&quot;Simulates Weak Law of Large Numbers for Bernoulli trials&quot;&quot;&quot;\n",
              "    samples = np.random.binomial(1, 0.5, (num_samples, n))\n",
              "    sample_means = samples.mean(axis=1)\n",
              "    stats = {\n",
              "        &quot;expected_mean&quot;: 0.5,\n",
              "        &quot;sample_means_mean&quot;: sample_means.mean(),\n",
              "        &quot;sample_means_var&quot;: sample_means.var(),\n",
              "        &quot;chebyshev_bound&quot;: 1 / (4 * n * 0.05**2),  # For ε=0.05\n",
              "    }\n",
              "    return stats\n",
              "def high_dim_orthogonality(d: int, num_pairs: int = 1000) -&gt; dict:\n",
              "    &quot;&quot;&quot;Calculates inner product statistics in high dimensions&quot;&quot;&quot;\n",
              "    X = np.random.normal(0, 1, (num_pairs, d))\n",
              "    Y = np.random.normal(0, 1, (num_pairs, d))\n",
              "    norms_X = np.linalg.norm(X, axis=1)\n",
              "    norms_Y = np.linalg.norm(Y, axis=1)\n",
              "    cos_theta = np.sum(X * Y, axis=1) / (norms_X * norms_Y)\n",
              "    stats = {\n",
              "        &quot;mean_angle&quot;: np.mean(np.arccos(cos_theta)),\n",
              "        &quot;prob_above_0.1&quot;: np.mean(np.abs(cos_theta) &gt; 0.1),\n",
              "        &quot;chebyshev_bound&quot;: 1 / (d * 0.1**2),\n",
              "    }\n",
              "    return stats\n",
              "def johnson_lindenstrauss_project(X: np.ndarray, k: int) -&gt; np.ndarray:\n",
              "    &quot;&quot;&quot;Random projection matrix for JL Lemma&quot;&quot;&quot;\n",
              "    d = X.shape[1]\n",
              "    Q = np.random.normal(0, 1 / np.sqrt(k), (d, k))\n",
              "    return X @ Q\n",
              "with gr.Blocks(\n",
              "    css=&quot;&quot;&quot;gradio-app {background: #222222 !important}&quot;&quot;&quot;,\n",
              "    title=&quot;High-Dimensional Data Behavior&quot;,\n",
              ") as demo:\n",
              "    with gr.Tab(&quot;Chebyshev Inequality&quot;):\n",
              "        t_input = gr.Slider(0.01, 0.49, value=0.2, label=&quot;Threshold t&quot;)\n",
              "        cheb_plot = gr.Plot()\n",
              "        cheb_json = gr.JSON()\n",
              "\n",
              "        def update_cheb(t):\n",
              "            actual, bound, stats = chebyshev_uniform_demo(t)\n",
              "            fig = go.Figure()\n",
              "            fig.add_trace(\n",
              "                go.Scatter(x=np.linspace(0, 1, 100), y=[0.5] * 100, name=&quot;Mean&quot;)\n",
              "            )\n",
              "            fig.add_vrect(\n",
              "                x0=0.5 - t,\n",
              "                x1=0.5 + t,\n",
              "                fillcolor=&quot;green&quot;,\n",
              "                opacity=0.2,\n",
              "                name=&quot;Acceptance&quot;,\n",
              "            )\n",
              "            fig.update_layout(title=&quot;Probability Concentration: Actual vs Bound&quot;)\n",
              "            cheb_json = stats\n",
              "            return fig, cheb_json\n",
              "\n",
              "        t_input.change(update_cheb, t_input, [cheb_plot, cheb_json])\n",
              "\n",
              "    with gr.Tab(&quot;Weak Law of Large Numbers&quot;):\n",
              "        n_input = gr.Slider(10, 1000, value=100, step=10, label=&quot;Sample size n&quot;)\n",
              "        wlln_plot = gr.Plot()\n",
              "\n",
              "        def update_wlln(n):\n",
              "            means = [wlln_simulation(int(n))[&quot;sample_means_mean&quot;] for _ in range(100)]\n",
              "            fig = px.line(\n",
              "                x=range(100),\n",
              "                y=means,\n",
              "                labels={&quot;x&quot;: &quot;Trial&quot;, &quot;y&quot;: &quot;Sample Mean&quot;},\n",
              "                title=&quot;Convergence of Sample Means&quot;,\n",
              "            )\n",
              "            fig.add_hline(y=0.5, line_dash=&quot;dash&quot;)\n",
              "            return fig\n",
              "\n",
              "        n_input.change(update_wlln, n_input, wlln_plot)\n",
              "\n",
              "    with gr.Tab(&quot;High-D Orthogonality&quot;):\n",
              "        dim_input = gr.Slider(2, 1000, value=100, label=&quot;Dimension d&quot;)\n",
              "        angle_plot = gr.Plot()\n",
              "        angle_stats = gr.JSON()\n",
              "\n",
              "        def update_angles(d):\n",
              "            stats = high_dim_orthogonality(int(d))\n",
              "            angles = np.random.normal(0, 1 / np.sqrt(d), 1000)\n",
              "            fig = px.histogram(\n",
              "                angles, nbins=50, title=&quot;Distribution of cosθ in High Dimensions&quot;\n",
              "            )\n",
              "            angle_stats = stats\n",
              "            return fig, angle_stats\n",
              "\n",
              "        dim_input.change(update_angles, dim_input, [angle_plot, angle_stats])\n",
              "demo.launch(height=1000, pwa=True, show_api=False, show_error=True)\n",
              "\n",
              "        </gradio-lite>\n",
              "    </div>\n",
              "    "
            ]
          }
        }
      ],
      "source": [
        "from mds_2024w import nb_gradio\n",
        "\n",
        "nb_gradio()"
      ],
      "id": "048e34fb"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": ".venv",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  }
}