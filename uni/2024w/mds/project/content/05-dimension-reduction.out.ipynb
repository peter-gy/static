{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dimension Reduction"
      ],
      "id": "c9f3f65b-c352-423c-847d-aea567caedf6"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import load_breast_cancer, load_digits, load_iris, load_wine\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "id": "b0170efa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "High-dimensional data often contains redundancy, noise, and dependencies\n",
        "between features, making it challenging to analyze efficiently.\n",
        "**Dimension reduction** techniques aim to transform data from a\n",
        "high-dimensional space $\\mathbb{R}^d$ to a lower-dimensional\n",
        "representation $\\mathbb{R}^s$ while preserving its essential\n",
        "characteristics.\n",
        "\n",
        "Two common approaches to dimension reduction are:\n",
        "\n",
        "-   **Linear methods**: Principal Component Analysis (PCA)\n",
        "-   **Non-linear methods**: Kernel Principal Component Analysis (Kernel\n",
        "    PCA)\n",
        "\n",
        "This notebook explores both methods and provides an interactive tool to\n",
        "analyze real-world datasets.\n",
        "\n",
        "## Principal Component Analysis (PCA)\n",
        "\n",
        "Given a dataset $X = (x_1, \\dots, x_n) \\in \\mathbb{R}^{d \\times n}$, we\n",
        "assume zero mean $\\bar{x} = 0$. The goal of PCA is to find a new\n",
        "orthonormal basis that maximizes the variance of the projected data.\n",
        "\n",
        "1.  Compute the **covariance matrix**: $$\n",
        "    C = \\frac{1}{n} X X^T \\in \\mathbb{R}^{d \\times d}\n",
        "    $$\n",
        "\n",
        "2.  Solve the **eigenvalue problem**:\n",
        "\n",
        "$$\n",
        "C v_k = \\lambda_k v_k\n",
        "$$\n",
        "\n",
        "where $\\lambda_k$ and $v_k$ are eigenvalues and eigenvectors of $C$.\n",
        "\n",
        "1.  Select the top $s$ eigenvectors $V = (v_1, \\dots, v_s)$ to form the\n",
        "    **projection matrix**.\n",
        "\n",
        "2.  Compute the dimension-reduced data:\n",
        "\n",
        "$$\n",
        "Z = V^T X \\in \\mathbb{R}^{s \\times n}\n",
        "$$\n",
        "\n",
        "### Properties\n",
        "\n",
        "-   The variance of the projected data is maximized.\n",
        "-   The total variance explained by the top $s$ components is: $$\n",
        "    \\text{Var}(V^T X) = \\lambda_1 + \\dots + \\lambda_s\n",
        "    $$\n",
        "-   The approximation error of reconstructing $X$ from $Z$ is minimized.\n",
        "\n",
        "> We apply PCA to datasets such as **Iris, Digits, Breast Cancer, and\n",
        "> Wine** and visualize the low-dimensional representation.\n",
        "\n",
        "## Kernel Principal Component Analysis (Kernel PCA)\n",
        "\n",
        "PCA is limited to **linear** transformations, which might fail when data\n",
        "is **non-linearly separable**. **Kernel PCA** overcomes this by mapping\n",
        "data into a high-dimensional feature space $\\mathbb{R}^D$ using a kernel\n",
        "function $k(x, y)$, and then applying PCA in that space.\n",
        "\n",
        "1.  Define a feature map $\\Phi: \\mathbb{R}^d \\to \\mathbb{R}^D$ that\n",
        "    implicitly transforms the data:\n",
        "\n",
        "$$\n",
        "\\phi_i = \\Phi(x_i) \\in \\mathbb{R}^D\n",
        "$$\n",
        "\n",
        "1.  Compute the **kernel matrix**:\n",
        "\n",
        "$$\n",
        "K_{ij} = k(x_i, x_j) = \\langle \\Phi(x_i), \\Phi(x_j) \\rangle\n",
        "$$\n",
        "\n",
        "1.  Center the kernel matrix:\n",
        "\n",
        "$$\n",
        "\\tilde{K} = K - \\frac{1}{n} K 1_n - \\frac{1}{n} 1_n K + \\frac{1}{n^2} 1_n K 1_n\n",
        "$$\n",
        "\n",
        "1.  Solve the eigenvalue problem:\n",
        "\n",
        "$$\n",
        "n \\lambda_k \\alpha_k = \\tilde{K} \\alpha_k\n",
        "$$\n",
        "\n",
        "1.  Compute the principal components:\n",
        "\n",
        "$$\n",
        "Z = (\\alpha_1, \\dots, \\alpha_s)^T \\tilde{K}\n",
        "$$\n",
        "\n",
        "**Common Kernels**:\n",
        "\n",
        "-   **Linear kernel**: $k(x, y) = \\langle x, y \\rangle$\n",
        "-   **Polynomial kernel**: $k(x, y) = (\\langle x, y \\rangle + 1)^d$\n",
        "-   **RBF (Gaussian) kernel**: $k(x, y) = e^{-\\gamma \\|x - y\\|^2}$\n",
        "\n",
        "> Kernel PCA is applied to datasets to reveal non-linear structures in\n",
        "> data. The interactive tool allows users to compare PCA and Kernel PCA\n",
        "> with different kernels.\n",
        "\n",
        "## Python Implementation"
      ],
      "id": "3d526251-b219-4d36-be99-7c663ffa9031"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def svd_low_rank_approximation(A: np.ndarray, p: int) -> np.ndarray:\n",
        "    \"\"\"Compute pseudo-inverse using low-rank SVD approximation\"\"\"\n",
        "    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n",
        "    S_inv = np.diag(1 / s[:p])\n",
        "    return Vt[:p].T @ S_inv @ U[:, :p].T\n",
        "\n",
        "\n",
        "def compute_pca(X: np.ndarray, s: int) -> tuple[np.ndarray, dict]:\n",
        "    \"\"\"PCA implementation with variance explained metrics\"\"\"\n",
        "    X_centered = X - X.mean(axis=1, keepdims=True)\n",
        "    C = X_centered @ X_centered.T / X.shape[1]\n",
        "    eigvals, eigvecs = np.linalg.eigh(C)\n",
        "    idx = eigvals.argsort()[::-1]\n",
        "\n",
        "    V = eigvecs[:, idx][:, :s]\n",
        "    Z = V.T @ X_centered\n",
        "\n",
        "    metrics = {\n",
        "        \"explained_variance\": eigvals[idx][:s].tolist(),\n",
        "        \"total_variance_ratio\": eigvals[idx][:s].sum() / eigvals.sum(),\n",
        "    }\n",
        "    return Z, metrics\n",
        "\n",
        "\n",
        "def kernel_matrix(\n",
        "    X: np.ndarray, kernel: str, gamma: float = 1.0, degree: int = 2\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Compute centered kernel matrix with RBF/poly/linear kernels\"\"\"\n",
        "    n = X.shape[1]\n",
        "    K = np.zeros((n, n))\n",
        "\n",
        "    # Kernel computations\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if kernel == \"rbf\":\n",
        "                K[i, j] = np.exp(-gamma * np.linalg.norm(X[:, i] - X[:, j]) ** 2)\n",
        "            elif kernel == \"poly\":\n",
        "                K[i, j] = (X[:, i] @ X[:, j] + 1) ** degree\n",
        "            else:  # linear kernel\n",
        "                K[i, j] = X[:, i] @ X[:, j]\n",
        "\n",
        "    # Center kernel matrix\n",
        "    J = np.ones((n, n)) / n\n",
        "    K_centered = K - J @ K - K @ J + J @ K @ J\n",
        "    return K_centered\n",
        "\n",
        "\n",
        "def compute_kpca(\n",
        "    X: np.ndarray, kernel: str, s: int, **kernel_params\n",
        ") -> tuple[np.ndarray, dict]:\n",
        "    \"\"\"Kernel PCA implementation with automatic centering\"\"\"\n",
        "    K = kernel_matrix(X, kernel, **kernel_params)\n",
        "    eigvals, eigvecs = np.linalg.eigh(K)\n",
        "    idx = eigvals.argsort()[::-1]\n",
        "\n",
        "    alpha = eigvecs[:, idx][:, :s]\n",
        "    for i in range(s):\n",
        "        alpha[:, i] /= np.sqrt(eigvals[idx][i])  # Normalize eigenvectors\n",
        "\n",
        "    Z = alpha.T @ K\n",
        "    metrics = {\n",
        "        \"top_eigenvalues\": eigvals[idx][:s].tolist(),\n",
        "        \"kernel_matrix_sample\": K[:3, :3].tolist(),\n",
        "    }\n",
        "    return Z, metrics"
      ],
      "id": "7a5ee085"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "title": "[python]"
      },
      "outputs": [],
      "source": [
        "def create_projection_plot(Z: np.ndarray, labels: np.ndarray) -> go.Figure:\n",
        "    \"\"\"Create interactive 3D/2D visualization of projected data\"\"\"\n",
        "    dim = Z.shape[0]\n",
        "    if dim == 1:\n",
        "        Z = np.vstack([Z, np.zeros_like(Z)])\n",
        "\n",
        "    df = {\n",
        "        \"PC1\": Z[0],\n",
        "        \"PC2\": Z[1],\n",
        "        \"PC3\": Z[2] if dim > 2 else np.zeros_like(Z[0]),\n",
        "        \"Class\": labels.astype(str),\n",
        "    }\n",
        "\n",
        "    fig = (\n",
        "        px.scatter_3d(df, x=\"PC1\", y=\"PC2\", z=\"PC3\", color=\"Class\")\n",
        "        if dim > 2\n",
        "        else px.scatter(df, x=\"PC1\", y=\"PC2\", color=\"Class\")\n",
        "    )\n",
        "\n",
        "    fig.update_layout(height=600, scene_camera=dict(up=dict(x=0, y=0, z=1)))\n",
        "    return fig"
      ],
      "id": "e80dfa89"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Dashboard"
      ],
      "id": "57f92ef7-591b-483f-9764-213decb64e03"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_map = {\n",
        "    \"Breast Cancer\": load_breast_cancer,\n",
        "    \"Digits\": load_digits,\n",
        "    \"Iris\": load_iris,\n",
        "    \"Wine\": load_wine,\n",
        "}\n",
        "dataset_names = sorted(list(dataset_map.keys()))"
      ],
      "id": "2bc85e3e"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_data(\n",
        "    dataset_name: str,\n",
        "    method: str,\n",
        "    n_components: int,\n",
        "    kernel: str,\n",
        "    gamma: float,\n",
        "    degree: int,\n",
        ") -> tuple[go.Figure, dict]:\n",
        "    \"\"\"Main analysis function handling dataset loading and processing\"\"\"\n",
        "    # Load dataset\n",
        "    data = dataset_map[dataset_name]()\n",
        "    X = StandardScaler().fit_transform(data.data).T\n",
        "    labels = data.target\n",
        "\n",
        "    # Compute projections\n",
        "    if method == \"PCA\":\n",
        "        Z, metrics = compute_pca(X, n_components)\n",
        "        metric_key = \"PCA Metrics\"\n",
        "    else:\n",
        "        Z, metrics = compute_kpca(X, kernel, n_components, gamma=gamma, degree=degree)\n",
        "        metric_key = \"Kernel PCA Metrics\"\n",
        "\n",
        "    # Generate visualization\n",
        "    fig = create_projection_plot(Z, labels)\n",
        "    return fig, {metric_key: metrics}\n",
        "\n",
        "\n",
        "with gr.Blocks(\n",
        "    css=\"\"\"gradio-app {background: #222222 !important}\"\"\",\n",
        "    title=\"Dimension Reduction Explorer\",\n",
        ") as demo:\n",
        "    with gr.Row():\n",
        "        dataset = gr.Dropdown(dataset_names, label=\"Dataset\", value=dataset_names[0])\n",
        "        method = gr.Radio([\"PCA\", \"Kernel PCA\"], label=\"Method\", value=\"PCA\")\n",
        "        components = gr.Slider(1, 3, value=3, step=1, label=\"Components\")\n",
        "\n",
        "    with gr.Accordion(\"Kernel Parameters\", open=False):\n",
        "        kernel = gr.Dropdown([\"linear\", \"rbf\", \"poly\"], value=\"linear\", label=\"Kernel\")\n",
        "        gamma = gr.Slider(0.01, 1.0, value=0.005, label=\"RBF Gamma\", visible=False)\n",
        "        degree = gr.Slider(\n",
        "            1, 5, value=2, step=1, label=\"Polynomial Degree\", visible=False\n",
        "        )\n",
        "\n",
        "    analyze_btn = gr.Button(\"Analyze\", variant=\"primary\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Projection\"):\n",
        "            plot = gr.Plot(label=\"Data Projection\")\n",
        "        with gr.Tab(\"Metrics\"):\n",
        "            metrics = gr.JSON(label=\"Analysis Metrics\")\n",
        "\n",
        "    kernel.change(\n",
        "        lambda k: (gr.update(visible=k == \"rbf\"), gr.update(visible=k == \"poly\")),\n",
        "        inputs=kernel,\n",
        "        outputs=[gamma, degree],\n",
        "    )\n",
        "\n",
        "    analyze_btn.click(\n",
        "        analyze_data,\n",
        "        inputs=[dataset, method, components, kernel, gamma, degree],\n",
        "        outputs=[plot, metrics],\n",
        "    )"
      ],
      "id": "33aa8157"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "demo.launch(pwa=True, show_api=False, show_error=True)"
      ],
      "id": "80caece1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "    <div style=\"width: 100%;\">\n",
              "        <script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n",
              "        <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n",
              "        <style>\n",
              "            gradio-lite {\n",
              "                background: #222222 !important;\n",
              "                border: white 1px solid !important;\n",
              "                width: 100% !important;\n",
              "            }\n",
              "            .column {\n",
              "                width: 100% !important;\n",
              "            }\n",
              "        </style>\n",
              "        <gradio-lite>\n",
              "import micropip\n",
              "await micropip.install(&#x27;plotly==5.24.1&#x27;);\n",
              "\n",
              "\n",
              "import gradio as gr\n",
              "import numpy as np\n",
              "import plotly.express as px\n",
              "import plotly.graph_objects as go\n",
              "from sklearn.datasets import load_breast_cancer, load_digits, load_iris, load_wine\n",
              "from sklearn.preprocessing import StandardScaler\n",
              "def svd_low_rank_approximation(A: np.ndarray, p: int) -&gt; np.ndarray:\n",
              "    &quot;&quot;&quot;Compute pseudo-inverse using low-rank SVD approximation&quot;&quot;&quot;\n",
              "    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n",
              "    S_inv = np.diag(1 / s[:p])\n",
              "    return Vt[:p].T @ S_inv @ U[:, :p].T\n",
              "\n",
              "\n",
              "def compute_pca(X: np.ndarray, s: int) -&gt; tuple[np.ndarray, dict]:\n",
              "    &quot;&quot;&quot;PCA implementation with variance explained metrics&quot;&quot;&quot;\n",
              "    X_centered = X - X.mean(axis=1, keepdims=True)\n",
              "    C = X_centered @ X_centered.T / X.shape[1]\n",
              "    eigvals, eigvecs = np.linalg.eigh(C)\n",
              "    idx = eigvals.argsort()[::-1]\n",
              "\n",
              "    V = eigvecs[:, idx][:, :s]\n",
              "    Z = V.T @ X_centered\n",
              "\n",
              "    metrics = {\n",
              "        &quot;explained_variance&quot;: eigvals[idx][:s].tolist(),\n",
              "        &quot;total_variance_ratio&quot;: eigvals[idx][:s].sum() / eigvals.sum(),\n",
              "    }\n",
              "    return Z, metrics\n",
              "\n",
              "\n",
              "def kernel_matrix(\n",
              "    X: np.ndarray, kernel: str, gamma: float = 1.0, degree: int = 2\n",
              ") -&gt; np.ndarray:\n",
              "    &quot;&quot;&quot;Compute centered kernel matrix with RBF/poly/linear kernels&quot;&quot;&quot;\n",
              "    n = X.shape[1]\n",
              "    K = np.zeros((n, n))\n",
              "\n",
              "    # Kernel computations\n",
              "    for i in range(n):\n",
              "        for j in range(n):\n",
              "            if kernel == &quot;rbf&quot;:\n",
              "                K[i, j] = np.exp(-gamma * np.linalg.norm(X[:, i] - X[:, j]) ** 2)\n",
              "            elif kernel == &quot;poly&quot;:\n",
              "                K[i, j] = (X[:, i] @ X[:, j] + 1) ** degree\n",
              "            else:  # linear kernel\n",
              "                K[i, j] = X[:, i] @ X[:, j]\n",
              "\n",
              "    # Center kernel matrix\n",
              "    J = np.ones((n, n)) / n\n",
              "    K_centered = K - J @ K - K @ J + J @ K @ J\n",
              "    return K_centered\n",
              "\n",
              "\n",
              "def compute_kpca(\n",
              "    X: np.ndarray, kernel: str, s: int, **kernel_params\n",
              ") -&gt; tuple[np.ndarray, dict]:\n",
              "    &quot;&quot;&quot;Kernel PCA implementation with automatic centering&quot;&quot;&quot;\n",
              "    K = kernel_matrix(X, kernel, **kernel_params)\n",
              "    eigvals, eigvecs = np.linalg.eigh(K)\n",
              "    idx = eigvals.argsort()[::-1]\n",
              "\n",
              "    alpha = eigvecs[:, idx][:, :s]\n",
              "    for i in range(s):\n",
              "        alpha[:, i] /= np.sqrt(eigvals[idx][i])  # Normalize eigenvectors\n",
              "\n",
              "    Z = alpha.T @ K\n",
              "    metrics = {\n",
              "        &quot;top_eigenvalues&quot;: eigvals[idx][:s].tolist(),\n",
              "        &quot;kernel_matrix_sample&quot;: K[:3, :3].tolist(),\n",
              "    }\n",
              "    return Z, metrics\n",
              "def create_projection_plot(Z: np.ndarray, labels: np.ndarray) -&gt; go.Figure:\n",
              "    &quot;&quot;&quot;Create interactive 3D/2D visualization of projected data&quot;&quot;&quot;\n",
              "    dim = Z.shape[0]\n",
              "    if dim == 1:\n",
              "        Z = np.vstack([Z, np.zeros_like(Z)])\n",
              "\n",
              "    df = {\n",
              "        &quot;PC1&quot;: Z[0],\n",
              "        &quot;PC2&quot;: Z[1],\n",
              "        &quot;PC3&quot;: Z[2] if dim &gt; 2 else np.zeros_like(Z[0]),\n",
              "        &quot;Class&quot;: labels.astype(str),\n",
              "    }\n",
              "\n",
              "    fig = (\n",
              "        px.scatter_3d(df, x=&quot;PC1&quot;, y=&quot;PC2&quot;, z=&quot;PC3&quot;, color=&quot;Class&quot;)\n",
              "        if dim &gt; 2\n",
              "        else px.scatter(df, x=&quot;PC1&quot;, y=&quot;PC2&quot;, color=&quot;Class&quot;)\n",
              "    )\n",
              "\n",
              "    fig.update_layout(height=600, scene_camera=dict(up=dict(x=0, y=0, z=1)))\n",
              "    return fig\n",
              "dataset_map = {\n",
              "    &quot;Breast Cancer&quot;: load_breast_cancer,\n",
              "    &quot;Digits&quot;: load_digits,\n",
              "    &quot;Iris&quot;: load_iris,\n",
              "    &quot;Wine&quot;: load_wine,\n",
              "}\n",
              "dataset_names = sorted(list(dataset_map.keys()))\n",
              "def analyze_data(\n",
              "    dataset_name: str,\n",
              "    method: str,\n",
              "    n_components: int,\n",
              "    kernel: str,\n",
              "    gamma: float,\n",
              "    degree: int,\n",
              ") -&gt; tuple[go.Figure, dict]:\n",
              "    &quot;&quot;&quot;Main analysis function handling dataset loading and processing&quot;&quot;&quot;\n",
              "    # Load dataset\n",
              "    data = dataset_map[dataset_name]()\n",
              "    X = StandardScaler().fit_transform(data.data).T\n",
              "    labels = data.target\n",
              "\n",
              "    # Compute projections\n",
              "    if method == &quot;PCA&quot;:\n",
              "        Z, metrics = compute_pca(X, n_components)\n",
              "        metric_key = &quot;PCA Metrics&quot;\n",
              "    else:\n",
              "        Z, metrics = compute_kpca(X, kernel, n_components, gamma=gamma, degree=degree)\n",
              "        metric_key = &quot;Kernel PCA Metrics&quot;\n",
              "\n",
              "    # Generate visualization\n",
              "    fig = create_projection_plot(Z, labels)\n",
              "    return fig, {metric_key: metrics}\n",
              "\n",
              "\n",
              "with gr.Blocks(\n",
              "    css=&quot;&quot;&quot;gradio-app {background: #222222 !important}&quot;&quot;&quot;,\n",
              "    title=&quot;Dimension Reduction Explorer&quot;,\n",
              ") as demo:\n",
              "    with gr.Row():\n",
              "        dataset = gr.Dropdown(dataset_names, label=&quot;Dataset&quot;, value=dataset_names[0])\n",
              "        method = gr.Radio([&quot;PCA&quot;, &quot;Kernel PCA&quot;], label=&quot;Method&quot;, value=&quot;PCA&quot;)\n",
              "        components = gr.Slider(1, 3, value=3, step=1, label=&quot;Components&quot;)\n",
              "\n",
              "    with gr.Accordion(&quot;Kernel Parameters&quot;, open=False):\n",
              "        kernel = gr.Dropdown([&quot;linear&quot;, &quot;rbf&quot;, &quot;poly&quot;], value=&quot;linear&quot;, label=&quot;Kernel&quot;)\n",
              "        gamma = gr.Slider(0.01, 1.0, value=0.005, label=&quot;RBF Gamma&quot;, visible=False)\n",
              "        degree = gr.Slider(\n",
              "            1, 5, value=2, step=1, label=&quot;Polynomial Degree&quot;, visible=False\n",
              "        )\n",
              "\n",
              "    analyze_btn = gr.Button(&quot;Analyze&quot;, variant=&quot;primary&quot;)\n",
              "\n",
              "    with gr.Tabs():\n",
              "        with gr.Tab(&quot;Projection&quot;):\n",
              "            plot = gr.Plot(label=&quot;Data Projection&quot;)\n",
              "        with gr.Tab(&quot;Metrics&quot;):\n",
              "            metrics = gr.JSON(label=&quot;Analysis Metrics&quot;)\n",
              "\n",
              "    kernel.change(\n",
              "        lambda k: (gr.update(visible=k == &quot;rbf&quot;), gr.update(visible=k == &quot;poly&quot;)),\n",
              "        inputs=kernel,\n",
              "        outputs=[gamma, degree],\n",
              "    )\n",
              "\n",
              "    analyze_btn.click(\n",
              "        analyze_data,\n",
              "        inputs=[dataset, method, components, kernel, gamma, degree],\n",
              "        outputs=[plot, metrics],\n",
              "    )\n",
              "demo.launch(pwa=True, show_api=False, show_error=True)\n",
              "\n",
              "        </gradio-lite>\n",
              "    </div>\n",
              "    "
            ]
          }
        }
      ],
      "source": [
        "# Output of this cell set dynamically in Quarto filter step"
      ],
      "id": "08d5bbcc"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "title,-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": ".venv",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  }
}